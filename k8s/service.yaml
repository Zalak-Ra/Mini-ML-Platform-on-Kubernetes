apiVersion: v1
kind: Service
metadata:
  name: ml-inference
  namespace: ml-platform
  labels:
    app: ml-inference
spec:
  # ClusterIP: Internal cluster access only
  type: ClusterIP
  
  # Session affinity (optional)
  # sessionAffinity: ClientIP
  
  selector:
    app: ml-inference
  
  ports:
  - name: http
    protocol: TCP
    port: 80        # Service port (cluster-internal)
    targetPort: 8000 # Container port
  
  # Load balancing strategy
  # Default is round-robin across healthy pods
